{
  "basics": {
    "email": "tjtolton@gmail.com",
    "phone": "(717) 781-6668",
    "name": "Tyler Tolton",
    "summary": "Customer Value, Mathematical Rigor, Experimentation, Clear Communication, and Ownership.  These values define the critical pathway through which I have been successful in connecting business outcomes with highly motivated, highly performant teams.  Having been surrounded by and partnered with the very best in the fields of software, product led growth, data science, and team organization, I am uniquely positioned to help bring to life jaw dropping user experience or hockeysticking revenue stream - powered by data and delivered at scale.",
    "label": "Modeling Focused Machine Learning Engineer and Software Engineer",
    "picture": "",
    "website": "http://tylertolton.com",
    "profiles": [
      {
        "username": "Defunctionalize",
        "url": "http://github.com/Defunctionalize",
        "network": "Github"
      }
    ],
    "location": {
      "address": "1290 Country Club Road",
      "city": "York",
      "region": "Pennsylvania",
      "postalCode": "17403",
      "countryCode": "US"
    }
  },
  "certificates": [{
    "name": "AWS Machine Learning Specialty",
    "date": "2020-10-04",
    "issuer": "Amazon Web Services Training and Certification",
    "url": "https://www.credly.com/badges/4d3d8cea-a171-4759-9f49-3890257456a5"
  },{
    "name": "Deep Learning Specialization",
    "date": "2020-02-01",
    "issuer": "Coursera",
    "url": "https://www.coursera.org/account/accomplishments/specialization/TX5NKNCE858S"
  }
  ],
  "skills": [{
    "name": "Coding",
    "keywords": ["Python", "Clojure(script)", "ECMA6", "Rust", "Java", "C++", "C#", "Go"]

  },{
    "name": "Models used in Production",
    "keywords": ["W2V", "BERT", "Relu DNN", "RandomForest", "SVM", "KNN"]
  },{
    "name": "Python Libs",
    "keywords": ["PyTorch", "Pandas", "Numpy", "Sympy", "Sklearn", "Gensim"]
  },{
    "name": "Data Exploration",
    "keywords": ["Matplotlib", "Jupyter", "PCA", "Feature Importance"]
  },{
    "name": "ML Frameworks",
    "keywords": ["PyTorch", "SageMaker", "Dataiku"]
  },
  {
    "name": "AWS Cloud",
    "level": "Master",
    "keywords": ["SAM", "EC2", "Lambda", "DynamoDB", "ECR", "Cloudfront", "S3", "Cloudformation", "Sns", "Appsync"]

  },{
    "name": "Other Cloud",
    "keywords": ["GCE", "DivvyCloud/Rapid7", "Azure"]
  },
    {
    "name": "Analytics",
    "level": "Advanced",
    "keywords": ["Kafka", "Spark", "Flink", "Kappa", "Prometheus", "Kinesis"]
  },
    {
    "name": "Data Persistence",
    "level": "Advanced",
    "keywords": ["Redis", "Oracle", "Couchbase", "Cassandra", "Elasticsearch", "Postgresql", "Dynamodb", "Sql", "Mysql", "Redshift", "S3", "Graphql"]
  }
  ],
  "work": [
    {
      "endDate": "present",
      "highlights": [
        "Project 1: Led team of 5 in building RandomForest model to route support tickets, achieving 90% success rate, $12k in cost reduction per week",
        "Negotiated scope and timelines with product owners, achieved buy in on roadmaps and sprint backlogs, led sprint ceremonies and conducted one on one reviews with team",
        "Personally Performed business-logic-based and statistical feature engineering to identify 15 extracted columns concatenated with a 300 vector freetext embedding",
        "Hand wrote highly parallelized python preprocessing code to filter, normalize, deduplicate, tokenize and resample training data using pandas, numpy, swifter and dask",
        "After discovering model performed best on english sentences, wrote multi-threaded python code to pass dataset freetext fields though internal company translation API using requests library",
        "Additionally created the RESTful inference interface hosted via a python Flask app deployed onto load balanced production servers",
        "Trained W2V model from text8 dataset using gensim, fine tuned with internal ticket history corpus.  Adjusted hyperparameters and measured feature importance to find optimal embedding size",
        "Authored Ansible Playbooks which captured code changes and deployed models to development environment automatically and, when SDLC approved, promoted them to production behind blue/green sequence",
        "Implemented automated pipeline for monthly model retraining and comparison analysis using Ansible Tower and bash scripts",
        "Created Regression test suite based on customer reported misroutes, automatically run during deployment, gated deployment behind score thresholds, and sent emails to stakeholders",
        "After explosive growth in ticket volume due to Pfizer's role in the pandemic, re-engineered freetext embeddings using BERT model to capture more complex semantics",
        "Project 2: Led team of 6 in service health outage data enrichment model built using PyTorch and jupyter notebooks - improving service restoration time on average by 20%",
        "Drew up ML feature roadmaps in coordination with team of over 100 personnel with director level stakeholders across 6 different service towers responsible for all of Pfizer's critical lines of business",
        "Explored features from post ingestion analytics in jupyter notebooks with Python 3.",
        "Evaluated multiple models to create feature embeddings, including simple logistic regressors, additive trees, and DNNs - found DNN to be the most effective",
        "Used ML Framework Dataiku to engineer flows for training data ingestion, model versioning, and production inference",
        "Roadmapped feature growth plans for service outage prediction"
      ],
      "startDate": "2020-03-11",
      "position": "Senior Machine Learning Engineer",
      "company": "Pfizer, Inc."
    },
    {
      "endDate": "2019-07-13",
      "highlights": [
        "Principal Engineer, responsible for all technical roadmapping and delivery schedules",
        "Created recommendation feature to drive user engagement in liquidity asset platform, enabling 5x increase in average user network size over 4 months",
        "Personally responsible for all AWS lambda based production python code used for the platform's application backend microservices and analytics/ML pipeline",
        "Authored code to extract user and client company seed features from onboarding surveys (initially no-code generated in typeform, later custom react/cljs form) and captured usage analytics from platform engagement",
        "Used TDF-IDF of customer interests X client company features, used SVM to find cosine similarity, suggested most similar users to company CFO",
        "Implemented AWS Codebuild pipeline to deploy model and server code through dev into production",
        "Created serverless environment segregation system using cloudfront and api gateway to ensure dev calls and prod calls reached different code"
      ],
      "startDate": "2018-09-25",
      "summary": "Nth Round is an NEA backed startup that aims to provide a blockchain-powered secure marketplace for the resale of private equity among its clients' shareholders.",
      "position": "Full Stack Software Engineer",
      "company": "Nth Round, Inc."
    },
    {
      "endDate": "2018-06-01",
      "highlights": [
        "Designed Event Driven Analytics pathway with Kafka, Spark and Kinesis, increasing actionable business insight data by 250,000 events per day",
        "Created model based customer disambiguation and deduping report system, allowing 20k new users to be recognized and 70k duplicate users to be removed",
        "Used Python implemented fuzzy scoring algorithm to identify potential duplicates and to disambiguate records with invalid/phony contact info",
        "Potential dupes were submitted to external clients for reconciliation and used internally for recommendation",
        "Software Production Release Manager and Team Lead for v2 api design team"
      ],
      "startDate": "2016-09-01",
      "summary": "",
      "position": "Senior Full Stack Developer",
      "company": "Relay Network, LLC."
    },
    {
      "endDate": "2017-02-01",
      "highlights": [
        "Created Distributed Scheduler API using redis/couchbase",
        "Led daily standups with 8 person team focused horizontal delivery of apps to bank-wide users.",
        "Coded Python based KNN model workflow predictor to suggest runtime of jobs based on similar job history"
      ],
      "startDate": "2016-02-01",
      "summary": "The Saber2 dev team was an internal development task force charged with modernizing and replacing Bank of America's capital reporting platform, Saber",
      "position": "Senior Applications Developer",
      "company": "Bank of America"
    },
    {
      "endDate": "2016-01-01",
      "highlights": [
        "Architected reporting event emission pipeline",
        "Interviewed and hired key personnel for frontend software development",
        "Architected and implemented a GUI based, JSON driven cloud automation framework 'BotFactory' - scale tested for use with General Electric cloud computing.",
        "Designed unit test implementation strategy around 3 year old legacy code base cloud harvesting engine",
        "Created cloud testing framework tools for use with multiple asynchronous python processes",
        "Designed Clojure based microservice replacement architecture for use with cloud harvesting service.",
        "Designed a cloud simulation engine using jinja2 templating and XML responses in combination with a flask server."
      ],
      "startDate": "2015-04-01",
      "summary": "",
      "position": "Senior Backend Python Developer",
      "company": "Divvy Cloud"
    },
    {
      "endDate": "2015-02-01",
      "highlights": [
        "Unit testing using Pycharm Integrated nosetests and coverage, using Mock when needed.",
        "Developed a data migration feature using GZ File Compression and AES 256 encryption."
      ],
      "startDate": "2014-03-01",
      "position": "Python Developer",
      "company": "Freelance"
    },
    {
      "endDate": "2013-02-01",
      "highlights": [
        "Implemented LSFR algorithm to generate unique shortcodes for SMS messaging",
        "Architected robustness system for notifications when SMS carrier is unavailable",
        "Designed and implemented migration framework using petal - migrated from postgres into couchbase"
      ],
      "startDate": "2011-12-01",
      "position": "Python/Django/SQL Site Builder",
      "company": "Independent Contractor"
    }
  ],
  "meta": {"theme":  "paper"},
  "education": [
    {
      "institution": "Temple University",
      "startDate": "2011-01-01",
      "studyType": "Bachelor",
      "endDate": "2013-01-01",
      "area": "Accounting"
    }
  ]
}
